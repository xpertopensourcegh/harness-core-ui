createNewConnector: Create New Connector
confirmDeleteTitle: Delete Connector
editConnector: Edit the Connector
confirmDelete: Are you sure you want to delete the Connector
deletedSuccssMessage: 'Connector {{name}} deleted'
testInProgress: Test in progress
artifactRepository: ' Artifact {{ $.repository }}'
artifactRepoType: 'Artifact {{$.repositoryType}}'
specifyArtifactRepoType: 'Specify Artifact {{ $.repositoryType }}'
specifyArtifactRepo: 'Specify Artifact {{ $.repository }}'
newArtifactRepository: 'New Artifact Repository Connector'
selectConnectorLabel: Select Artifact Repository Connector
stepThreeName: '{{$.common.labelTestConnection}}'
stepFourName: 'Artifact Location'
name: Connector Name
updating: 'Updating Connector {{name}}'
creating: 'Creating Connector {{name}}'
successfullCreate: 'Connector {{name}} created successfully'
successfullUpdate: 'Connector {{name}} updated successfully'
connectorNotFound: Connector not found.
scopeError: 'Cannot create a Connector at {{createdAtScope}} scope from {{createdFromScope}} scope.'
createFromYaml: 'Create New Connector from YAML'
selectConnectivityMode: 'Select Connectivity Mode'
successfullyCreated: 'Connector created successfully'
secretManagerDetails: 'Secret Manager Details'
gcrConnectorDetails: 'Google Container Registry Overview'
hashicorpVaultDetails: 'HashiCorp Vault Overview'
appDynamicsDetails: 'AppDynamics Connector Details'
splunkConnectorDetails: 'Splunk Connector Details'
datadogConnectorDetails: 'Datadog Connector Details'
pagerDutyConnectorDetails: 'PagerDuty Connector Details'
sumoLogicConnectorDetails: 'SumoLogic Connector Details'
newRelicConnectorDetails: New Relic Connector Details
prometheusConnectorDetails: Prometheus Connector Details
customConnectorDetails: Custom Health Connector Details
prometheusLabel: Prometheus
dynatraceLabel: Dynatrace
appdLabel: AppDynamics
newRelicLabel: New Relic
splunkLabel: Splunk
customLabel: Custom Health
stackdriverMetricsLabel: Google Cloud Operations (Metrics)
stackdriverLogsLabel: Google Cloud Operations (Logs)
click: 'Click'
dynatraceConnectorDetails: Dynatrace Connector Details
connectorDetailsHeader: '{{type}} Connector Details'
addConnectorDetails: Add {{type}} Verification Provider
unableToCreateConnector: Unable to create Connector
unableToUpdateConnector: Unable to update Connector
encryptedAPIKeyLabel: Encrypted API Key
encryptedAPIKeyValidation: Encrypted API Key is required.
tenantId: Tenant Id
tenantIdRequired: Tenant Id is required
reportNameRequired: '{{ $.common.reportNameRequired }}'
connectorAlreadyExist: Connector already exists for the cloud account
loginToMasterAccount: and login to your master account
roleARN: Create Cross Account Role
ifReq: if required.
selectConnector: Select Connector
showInstructions: Show instructions
apiKey: '{{$.common.apikey}}'
apiKeyOrPassword: Password/Api Key
costVisibility: Cost Visibility
chooseMethodForK8sConnection: Choose the method for Harness to use when connecting to the cluster.
chooseMethodForGCPConnection: Choose the method for Harness to use when connecting to GCP.
delegateInClusterInfo: 'Use the credentials of a specific Harness Delegate (IAM role, service account, etc)'
createConnector: 'Create a Connector'
connectorEmptyState: 'There are no connectors in your project'
readMore: 'Read more'
connectorsTitle: 'Resources: Connectors'
parameters: Parameters
validationPath: Validation Path
addHeader: Add Header
addParameter: Add Parameter
baseURL: Base URL
requestMethod: Request Method
connectivityMode:
  title: 'Connectivity Mode'
  validation: 'Please select connectivity mode'
  connectToProvider: 'Connect to the provider'
  selectText: 'Select how you would like to connect to the provider'
title:
  k8sCluster: 'Kubernetes Cluster'
  gcpConnector: 'Google Cloud Provider'
  helmConnector: 'HTTP Helm Repo'
  gitConnector: 'Git Connector'
  githubConnector: 'GitHub Connector'
  gitlabConnector: 'GitLab Connector'
  bitbucketConnector: 'Bitbucket Connector'
  hashicorpVault: 'HashiCorp Vault'
  jira: 'Jira'
  serviceNow: 'ServiceNow'
  secretManager: 'Secret Manager'
  appdynamics: 'AppDynamics Connector'
  splunk: 'Splunk Connector'
  aws: 'AWS Cloud Provider'
  awsCodeCommit: 'AWS CodeCommit'
  nexus: 'Nexus Repository'
  artifactory: 'Artifactory Repository'
  awsKms: 'AWS Key Management Service'
  awsSecretManager: 'AWS Secrets Manager'
  delegateSelection: 'Delegate Selection'
  ceAzureConnector: 'Azure Connector'
  datadog: 'Datadog'
  azureKeyVault: 'Azure Key Vault'
  sumologic: 'SumoLogic'
  ceAws: 'AWS Connector '
  gcpKms: GCP Key Management Service
  errorTracking: 'Error Tracking'
name_labels:
  Kubernetes: 'Kubernetes Connector Name'
  HttpHelmRepo: 'Helm Http Connector Name'
  Git: 'Git Connector Name'
  Github: 'GitHub Connector Name'
  Gitlab: 'GitLab Connector Name'
  Bitbucket: 'Bitbucket Connector Name'
  Docker: 'Docker Connector Name'
  GCP: 'GCP Connector Name'
  gcpKms: 'GCP KMS Connector Name'
  AWS: 'AWS Connector Name'
  AwsCodeCommit: 'AWS CodeCommit Name'
  ECR: ECR Connector Name'
  Nexus: 'Nexus Connector Name'
  Artifactory: 'Artifactory Connector Name'
  SecretManager: 'Secret Manager Name'
  AppDynamics: 'AppDynamics Connector Name'
  Splunk: 'Splunk Connector Name'
testConnectionStep:
  errorDetails: Click to view error details
  noDelegate: Unable to get Delegate information
  executingOn: 'Executed on : '
  verificationSuccessful: Verification successful
  viewPermissions: View permissions required
  installNewDelegate: Install new Delegate
  placeholderError: Test failed for the Connector
  url:
    k8s: 'Master URL : '
    docker: 'Docker Registry URL : '
    artifactory: 'Artifactory Repository URL : '
    nexus: 'Nexus Repository URL : '
    splunk: 'Splunk URL : '
    appD: 'Controller URL : '
    vault: 'Vault URL : '
    bitbucket: 'URL : '
    gcr: 'GCR URL : '
  validationText:
    k8s: Validating the reachability of provided URL
    docker: Validating Docker Registry authentication and permissions
    artifactory: Validating Artifactory Repository authentication and permissions
    nexus: Validating Nexus Repository authentication and permissions
    gcp: Validating Google Cloud Provider authentication and permissions
    gcr: Validating Google Container Registry authentication and permissions
    aws: Validating the AWS Cloud Provider authentication and permissions
    appD: Validating AppDynamics authentication and permissions
    splunk: Validating Splunk authentication and permissions
    vault: Validating HashiCorp Vault authentication and permissions
    awsSecretManager: Validating AWS Secret Manager authentication and permissions
    bitbucket: Validating Bitbucket authentication and permissions
    gitlab: Validating GitLab authentication and permissions
    github: Validating GitHub authentication and permissions
    git: Validating Git authentication and permissions
    azure: Validating Azure authentication and permissions
    datadog: Validating Datadog authentication and permissions
    pagerduty: Validating PagerDuty authentication and permissions
    azureKeyVault: Validating Azure key vault authentication and permissions
    jira: Validating Jira authentication and permissions
    serviceNow: Validating ServiceNow authentication and permissions
    sumologic: Validating Sumologic authentication and permissions
    gcpKms: Validating GCP Key Management Service authentication and permissions
    testingURLReachability: Testing reachability to the URL
validation:
  serviceNowUrl: 'ServiceNow URL is required.'
  personalAccessToken: Personal Access Token is required
httpHelm:
  httpHelmRepoUrl: 'Helm Repo URL'
jira:
  jiraUrl: 'Jira URL'
serviceNow:
  serviceNowUrl: 'ServiceNow URL'
k8:
  delegateOutClusterInfo: 'Specify master URL and credentials'
  delegateInClusterInfo: '{{ $.connectors.delegateInClusterInfo }}'
  masterUrlLabel: 'Master URL'
  serviceAccountToken: 'Service Account Token'
  serviceAccountKey: 'Service Account Key'
  skipDefaultValidation: 'Skip default namespace validation'
  OIDCIssuerUrl: OIDC Issuer URL
  OIDCUsername: 'OIDC Username'
  OIDCPassword: 'OIDC Password'
  OIDCClientId: 'OIDC Client Id'
  OIDCSecret: 'OIDC Secret'
  clientSecretOptional: 'Client Secret (optional)'
  OIDCScopes: 'OIDC Scopes (optional)'
  clientKey: 'Client Key'
  clientKeyPassphrase: 'Client Key Passphrase (optional)'
  clientCertificate: 'Client Certificate'
  clientKeyAlgorithm: 'Client Key Algorithm'
  clientKeyAlgorithmPlaceholder: Select or Enter a Client Key Algorithm
  clientKeyCACertificate: 'CA Certificate (optional)'
  placeholder:
    masterUrl: '/URL'
  authLabels:
    OIDC: 'OpenID Connect'
    clientKeyCertificate: 'Client Key Certificate'
  validation:
    clientKeyAlgo: Client Key Algorithm is required
hashiCorpVault:
  appRole: App Role
  appRoleId: 'App Role Id'
  baseSecretPath: 'Base Secret Path (optional)'
  secretId: 'Secret Id'
  stepTwoName: 'HashiCorp Vault Details'
  vaultUrl: 'Vault URL'
  secretEngine: Secret Engine
  engineName: 'Secret Engine Name'
  engineVersion: 'Secret Engine Version'
  renewal: 'Renewal Interval (minutes)'
  readOnly: '{{$.common.readOnly}}'
  readOnlyVault: 'Read-only Vault'
  default: '{{$.common.default}}'
  defaultVault: 'Use as Default Secrets Manager'
  fetchEngines: Fetch Engines
  setupEngine: Setup Engine
  saveInProgress: Saving Connector Details
  manuallyConfigureEngine: Manually Configure Engine
  vaultAgent: Vault Agent
  awsAuth: AWS Auth
  serverIdHeader: Server Id Header
  serverIdHeaderRequired: Server Id Header is required
  root: '/(Root)'
  sinkPath: Sink Path
  sinkPathIsRequired: Sink Path is required
  k8s_auth: 'Kubernetes Auth'
  vaultK8sAuthRole: Role Name
  serviceAccountTokenPath: Service Account Token Path
  vaultK8sAuthRoleRequired: Role Required
  serviceAccountRequired: Service Account Token Path Required
nexus:
  nexusLabel: Nexus
  nexusServerUrl: 'Nexus Repository URL'
artifactory:
  artifactoryLabel: Artifactory
  artifactoryServerUrl: 'Artifactory Repository URL'
GCP:
  delegateOutClusterInfo: 'Specify credentials here'
  delegateInClusterInfo: '{{ $.connectors.delegateInClusterInfo }}'
ECR:
  name: ECR
  fullName: ECR Container Registry
GCR:
  name: GCR
  fullName: Google Container Registry
  artifactServer: 'GCR Server'
  stepTwoName: 'Google Container Registry Details'
  registryHostname: 'GCR Registry URL'
GCS:
  name: GCS
  fullName: Google Cloud Storage
S3: S3
docker:
  dockerRegistryURL: 'Docker Registry URL'
  dockerProvideType: 'Provider Type'
  dockerHub: 'DockerHub'
  harbour: 'Harbour'
  quay: 'Quay'
  other: 'Other (Docker V2 compliant)'
  dockerRepository: Docker Repository
helmRepo:
  helmRepoUrl: 'Helm Repository URL'
aws:
  awsAccessKey: AWS Access Key
  accessKey: '{{ $.common.accessKey }}'
  secretKey: '{{ $.common.secretKey }}'
  enableCrossAcc: Enable cross-account access (STS Role)
  crossAccURN: Cross account role ARN
  externalId: External Id (Optional)
  assumeIAMRole: Assume IAM role on Delegate
  useIRSA: Use IRSA
  validation:
    delegateSelector: 'Delegate Tag is required'
    secretKeyRef: 'Secret key is required'
    accessKey: 'Access key is required'
    crossAccountRoleArn: 'Role ARN is required'
awsCodeCommit:
  repoUrl: 'AWS CodeCommit Repository URL'
appD:
  connectionDetailsHeader: AppDynamics Connection Details
  apiClient: API Client
  clientId: '{{ $.common.clientId }}'
  controllerURL: Controller URL
  accountName: '{{ $.common.accountName }}'
  validation:
    controllerURL: Controller URL is a required field
    clientId: Client Id is a required field
    clientSecret: Client Secret is a required field
newRelic:
  subTitle: To add New Relic Connector, you will need access to New Relic Insights API. Verification analysis is limited to APM only.
  urlFieldLabel: New Relic URL
  accountIdFieldLabel: New Relic Account Id
  urlValidation: New Relic URL is required.
  accountIdValidation: New Relic Account Id is required.
  accountIdTooltip: For steps to get New Relic Account Id
  products:
    fullStackObservability: 'Full Stack Observability: APM'
prometheus:
  urlValidation: Prometheus URL is required.
datadog:
  encryptedAPPKeyLabel: Encrypted APP Key
  urlValidation: Datadog URL is required.
  encryptedAPPKeyValidation: Encrypted APP Key is required.
errorTracking:
  urlValidation: Error Tracking URL is required.
dynatrace:
  apiToken: API Token
  apiTokenValidation: API Token is required.
  urlValidation: Dynatrace URL is required.
sumologic:
  urlLabel: Sumo Logic API Server URL
  encryptedAccessIdLabel: Encrypted Access Id
  encryptedAccessKeyLabel: Encrypted Access Key
  urlValidation: SumoLogic URL is required.
  encryptedAccessIdValidation: SumoLogic Access Id is required.
  encryptedAccessKeyValidation: SumoLogic Access Key is required.
customHealth:
  baseURL: Base URL is required.
  requestBody: Request Body is required for POST requests.
  requestMethod: Request Method is required.
  validationPath: Validation Path is required.
  valueRequired: Value is required.
  keyRequired: Key is required.
cdng:
  jobName: Job Name
  continousVerificationType: Continous Verification Type
  artifactTag: Artifact Tag
  defineVerificationJob: Define Verification Job
  baseline: Baseline
  trafficsplit: Traffic Split (OPTIONAL)
  continousVerificationStep: Verify Step Details
  displayName: Display Name
  createCVJob: Please create a verification job
  loadingJobs: Loading verification jobs…
  noJobsConfigured: No verification jobs are configured.
  selectTheJobNameFirst: Please select the job name first by clicking on Define Verification Job Panel
  error: Something went wrong , please try again by clicking on CV step again
  monitoredService:
    label: Monitored Service
    fetchingMonitoredService: Fetching Monitored service ...
    creatingMonitoredService: Creating Monitored service ...
    fetchingMonitoredServiceError: Failed to fetch monitored service . Please try again by reopening the Verify Step
    autoCreateMonitoredService: Click to autocreate a monitored service
    creatingMonitoredServiceError: Failed to create monitored service . Please try again by reopening the Verify step and selecting service, environment.
    monitoredServiceText: A monitored service for the
    backToVerifyStep: Back to Verify Step
  runTimeMonitoredService:
    pleaseSpecify: Please specify
    toFetchMonitoredService: to fetch the monitored service.
    fetchingMonitoredServiceError: Failed to fetch monitored service . Please try again by re-running the Pipeline
    noMonitoringSercvicePresent: No Monitored Service is present for selected service and environment. Verify step will be skipped.
    noHealthSourcePresent: No Health source is present . Verify step will be skipped.
    backToRunPipeline: Back to Run Pipeline
  healthSources:
    label: Health Sources
    noHealthSourcesDefined: No health sources have been defined. To complete the verification, you would need at least one healthsource added.
  validations:
    deploymentTagRequired: Deployment Tag is required
    jobNameRequired: Job name is required
    durationRequired: Duration is required
    sensitivityRequired: Sensitivity is required
    verificationTypeRequired: Verification type is required
    monitoringServiceRequired: Monitored Service is required
    healthSourceRequired: At least one health source is required
    timeoutValidation: Timeout should be at least 40 minutes
  verificationSensitivityLabel:
    high: High
    medium: Medium
    low: Low
  baselineDefaultLabel:
    lastSuccess: Last Successful job run
  jobTypes:
    test: TEST
    blueGreen: BLUE_GREEN
    canary: CANARY
    health: HEALTH
connectAndSave: Connect and Save
connectorDetails: Connector Details
verifyConnection: Verify connection
createdSuccessfully: 'Connector {{name}} created successfully'
updatedSuccessfully: 'Connector {{name}} updated successfully'
splunk:
  connectorDetailsHeader: Splunk Connection Details
awsSecretManager:
  secretNamePrefix: Secret Name Prefix
gcpKms:
  keyRing: Key Ring
  keyName: Key Name
  credentialsFile: GCP KMS Credentials File
  keyRingRequired: Key Ring is required
  keyNameRequired: Key Name is required
  credentialsFileRequired: Credentials file is required
awsKms:
  accessKeyLabel: 'AWS - Access Key Id'
  secretKeyLabel: 'AWS - Secret Access Key'
  arnLabel: 'AWS ARN'
  roleArnLabel: 'Role ARN'
  assumedRoleDuration: 'Assumed Role Duration (seconds)'
  loggedAt: 'Logged at'
  validation:
    selectDelegate: 'Please select a Delegate'
    selectRegion: 'Please select a Region'
    selectAWSArn: 'AWS ARN is required'
    durationNumber: 'Duration must be between 900 and 43200 seconds'
    durationError: 'Duration must be a number'
    externalIdRegexError: 'External Id can have upper and lower case alphanumeric characters with no spaces. You can also include underscores or any of the following characters: =,.@:/-'
    externalIdLengthError: 'External Id must have between 2 and 1224 characters'
  awsSTS: 'Assume Role using STS on Delegate'
delegate:
  configure: Configure what Delegates are allowed to connect to this Connector
  delegateSelectorAny: Connect via any available Delegate
  delegateSelectorSelective: Connect only via Delegates with all of the following tags
  hearbeat: heartbeat
  matchesSelectors: Matches
  testDelegateConnectivity: Test Delegate Connectivity
  matchingDelegates: matching Delegates
  waitingForConnection: Waiting for connection
  noDelegates: You have no Delegates
  noMatchingDelegate: No eligible Delegates found. Install a new Delegate or continue to save.
  delegateselectionPlaceholder: Select or Enter Delegates
  noMatchingDelegatesActive: None of the matching Delegates are in active state.
  couldNotFetch: Failed to update the Delegate list, Will try again in {{pollingInterval}}
  delegateSelectors: Delegate Selectors
ceK8:
  infoText: 'If you have previously created a connector to the preferred cluster for any of the other modules, you may reference the same connector here and create a connector for Cloud cost management. If this is the first time creating a connector to this cluster, you may proceed without referencing.'
  selectConnectorLabel: 'Reference an existing CD Kubernetes connector'
  overview:
    createNewConnectorCta: 'Create a new connector'
  chooseRequirements:
    heading: '{{ $.connectors.ceAws.steps.req }}'
    subheading: '{{ $.connectors.ceAws.crossAccountRoleStep1.description }}'
    description: '(Deep Kubernetes cost Visibility is selected by default. Select the other option to enable Intelligent Cloud AutoStopping for Kubernetes)'
    fixFeaturesDescription: 'Both the options below are required for Kubernetes AutoStopping and are selected by default. Click Continue to proceed.'
    visibility:
      heading: 'DEEP KUBERNETES'
      subheading: '{{ $.connectors.costVisibility }}'
      description: '<ul><li>Costs by pods, nodes, namespaces, workloads </li><li> Idle and unallocated cluster costs</li><li> Cost anomaly detection</li><li> Workload recommendations</li><li> Node recommendations</li><li> Budgets and alerts</li></ul>'
    optimization:
      heading: 'KUBERNETES OPTIMIZATION BY'
      subheading: '{{ $.common.ce.autostopping }}'
      description: '<ul><li>Works for custom clusters and EKS, AKS, GKE, etc</li><li> Orchestrate pods based on idleness</li><li> Set dependencies between workloads like pods, VMs, etc.</li><li> Granular savings visibility</li><li> Simple one-time setup</li></ul>'
  secretCreationStep:
    step1: 'Create an API key'
    step2: 'Run the following command to create a namespace'
    step3: 'Replace the API key in the following YAML'
    step4: 'Run the following command to apply the YAML and create a secret'
    namespaceCommand: 'kubectl create namespace harness-autostopping'
    creationCommand: 'kubectl apply -f secret.yaml'
  providePermissionsStep:
    heading: 'Provide Permissions - Download YAML'
    info: 'If you are using a EKS, ensure that the metrics server is installed on your Kubernetes cluster. '
    downloadYamlText: 'To provide required permissions to your cluster, please download the YAML below and continue to apply it using instructions given in the next step. You can preview the YAML file '
    fileDescription:
      heading: 'This YAML file contains:'
      info1: 'Creation of a delegate'
      info2: 'Permissions to access the pods and services of the cluster'
      info3: 'Installing components to create Autostopping rules'
      info4: 'Permissions to start and stop services as per rules'
    downloadYamlBtnText: 'Download YAML'
    downloadComplete: 'Download Complete'
    applyDelegateText: 'Copy the downloaded YAML to a machine where you have kubectl installed and have access to your Kubernetes cluster. Run the following command to apply the Harness delegate to your Kubernetes Cluster'
    successfulCommandExec: 'Command executed successfully'
  featureWarning: You have used {{count}} / {{limit}} free clusters incuded in your current plan. Consider upgrading for unlimited clusters.
azureKeyVault:
  labels:
    tenantId: '{{ $.connectors.tenantId }}'
    subscription: '{{ $.common.plans.subscription }}'
    vaultName: Vault Name
    fetchVault: Fetch Vault
    setupVault: Setup Vault
  validation:
    tenantId: '{{ $.connectors.tenantIdRequired }}'
    subscription: Subscription is required
    vaultName: Vault Name is required
ceAws:
  steps:
    overview: '{{ $.overview }}'
    cur: 'Cost and Usage Report'
    req: 'Choose Requirements'
    roleARN: '{{ $.connectors.roleARN }}'
    test: '{{ $.common.labelTestConnection }}'
  overview:
    heading: '{{ $.overview }}'
    awsAccountId: 'Specify the AWS account ID'
    alreadyExist: ' {{ $.connectors.connectorAlreadyExist }} '
    alreadyExistInfo: 'The cloud account {{awsAccountID}} already has a Connector “{{existingConnectorName}}” linked to it. The Connector has permission for {{featureText}}'
    trySuggestion: '{{ $.common.errorHandler.tryTheseSuggestions }}'
    editConnector: '{{ $.connectors.editConnector }}'
    ifReq: '{{ $.connectors.ifReq }}'
    validation:
      numeric: 'AWS Account Id must be numeric'
      positive: 'AWS Account Id must be a positive number'
      required: 'AWS Account Id is required'
  cur:
    heading: '{{ $.connectors.ceAws.steps.cur }}'
    subheading: 'Cost and Usage Report provides detailed billing data across AWS accounts to help you analyze your spend.'
    followInstruction: 'Please follow the instructions to provide access to the Cost and Usage Report'
    launchTemplate: 'Launch AWS console'
    login: 'and login to your account'
    createNew: 'Create new Cost and Usage report'
    reportName: 'Cost and Usage Report Name'
    bucketName: 'Cost and Usage S3 Bucket Name'
    instructions:
      i1: Login to your AWS account if not logged in already.
      i2: Follow these
      i3: ' instructions to create the Cost and Usage Report '
      i4: Enter Cost and Usage Report name and S3 bucket name below.
    validation:
      reportRequired: '{{ $.common.reportNameRequired }}'
      bucketRequired: 'Bucket name is required'
    noAccountLink: 'Don’t have access to add an AWS account?'
  curExising:
    subHeading: 'The following {{ reportCount }} Cost and Usage Reports are connected with your Harness Account.'
    accountID: 'Account ID '
    nextStepHint1: 'If the AWS Account ID you entered is covered by part of any of the above click “Continue >” to proceed. '
    nextStepHint2: 'If not, create a new one: '
    searchCUR: Enter Cost and Usage Report Name
  curExtention:
    heading: 'How to Create Cost and Usage Report?'
    subtext: 'Once logged into the AWS console'
    stepA:
      heading: 'Creating a Report'
      step1:
        p1: 'Create Report'
        p2: 'and provide a Cost and Usage Report Name. Copy this and paste it in the space provided on the left.'
      step2: 'Check Include resource IDs and keep other selections as it is.'
      step3: 'Click Next.'
    stepB:
      heading: 'Delivery options'
      step1:
        p1: 'Configure'
        p2: 'to create an S3 bucket.'
      step2: 'Provide an S3 bucket name and select Region (preferably US East - N.Virginia).'
      step3:
        p1: ', then click '
      step4: 'Enter a Report path prefix.'
      step5:
        heading: 'Configure the report with the following configuration:'
        subStep1:
          p1: 'Time granularity: '
          p2: 'Hourly '
        subStep2:
          p1: 'Report versioning: '
          p2: 'Overwrite Existing Report Version'
        subStep3: 'You do not need to enable any report data integrations.'
        subStep4:
          p1: 'Compression: '
          p2: 'GZIP'
      step6:
        p1: '{{ $.connectors.ceAws.curExtention.stepB.step3.p1 }}'
        p2: 'Review and Complete'
      step7: 'Copy and enter S3 bucket name.'
    moreHelp:
      heading: 'More help:'
      step1: '{{$.connectors.ceAzure.billing.extension.video}}'
      step2: '{{$.connectors.ceAzure.billing.extension.docs}}'
      step3: 'Creating Cost and Usage Reports'
      step4: 'Billing and Cost Management Policy Examples'
  crossAccountRoleStep1:
    heading: '{{ $.connectors.ceAws.steps.req }}'
    subHeading:
      'Harness uses the secure cross-account role to access your AWS account. The role includes a restricted policy to
      access the cost and usage reports and resources for the sole purpose of cost analysis and cost optimization'
    description: 'Select the Cloud Cost Management features that you would like to enable.'
    info: 'Cost visibility of the resources for which you added the CUR in the previous step is enabled by default. Select the others as per your requirements.'
    cost: 'Cost'
    visibility: '{{ $.common.ce.visibility }}'
    optimization: '{{ $.common.ce.optimization }}'
    visibilityDes: '{{ $.connectors.ceAzure.chooseRequirements.visibilityCardDesc }}'
    optimizationDes: '{{ $.connectors.ceAzure.chooseRequirements.optimizationCardDesc }}'
    default:
      feat1: AWS costs by services, accounts, etc.
      footer: from Cost and Usage Report
    visible:
      feat1: EC2, EBS and snapshot inventory dashboards
      feat2: ECS cluster cost, tasks, lauchtype details
      prefix: AWS ECS & RESOURCE
      heading: Inventory management
    optimize:
      feat1: Orchestrate VMs and ASGs based on idleness
      prefix: AWS OPTIMIZATION BY
      footer: to IAM role
  crossAccountRoleStep2:
    heading: '{{ $.connectors.roleARN }}'
    subHeading: '{{ $.connectors.ceAws.crossAccountRoleStep1.subHeading }}'
    instructions:
      i1: 'Launch the CloudFormation Template on the AWS console: '
      i2: '(You can preview the template '
      templateRedirection: here
      i3: '{{ $.connectors.ceAws.cur.instructions.i1 }}'
      i4: ' instructions to create the Cross Account Role '
      i5: Enter Cross Account Role ARN and External ID below.
    launchTemplate: 'Launch Template on AWS console'
    followInstructions: 'and follow the instuctions given on the right'
    roleArn: Cross Account Role ARN
    extId: 'External ID'
    dontHaveAccess: '{{ $.connectors.ceAws.cur.noAccountLink }}'
    validation:
      roleArnPattern: 'Role ARN does not match the pattern'
      roleArnRequired: 'Role ARN is Required'
  crossAccountRoleExtention:
    heading: 'Create cross-account IAM role using AWS CloudFormation template'
    subHeading: 'Launch the template in the AWS console to create stack'
    step1:
      p1: 'You can '
      p2: 'Preview Template'
      p3: ' to understand all the permissions involved.'
    step2:
      heading: 'Review and Lauch Harness specified AWS CloudFormation template on AWS console'
      subStep1: 'Click on the checkbox to acknowledge the IAM role creation.'
      subStep2:
        p1: 'Click on '
        p2: 'Create stack'
    step3:
      p1: 'On stack details page click on '
      p2: 'Outputs'
      p3: 'tab and copy '
      p4: 'CrossAccountRoleArn'
    step4: 'Provide that IAM ARN in Harness UI.'
    step5: 'External Id is a random unique value to provide additional secure authentication.'
  testConnection:
    heading: '{{ $.common.labelTestConnection }}'
    step1: 'Validating AWS Cloud Provider authentication'
    step2: 'Verifying the CUR report and S3 bucket name '
    step3: 'Validating the Cross-account role ARN '
ceAzure:
  guidPlaceholder: 'xxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx'
  guidRegexError: 'It has to match GUID pattern. Example: "123e4567-e89b-12d3-a456-9AC7CBDCEE52"'
  steps:
    overview: '{{ $.overview }}'
    billingExports: Azure Billing Exports
    requirements: '{{ $.connectors.ceAws.steps.req }}'
    servicePrincipal: Create Service Principal
    testConnection: '{{ $.common.labelTestConnection }}'
  overview:
    heading: '{{ $.overview }}'
    tenantId: Azure Tenant ID
    subscriptionId: Azure Subscription ID
    alreadyExist: '{{ $.connectors.connectorAlreadyExist }}'
    existingConnectorInfo: The cloud account {{accountId}} already has a Connector “{{name}}” linked to it. The Connector has permissions for {{featureText}}.
    trySuggestion: '{{ $.common.errorHandler.tryTheseSuggestions }}'
    editConnector: '{{ $.connectors.editConnector }}'
    required: '{{ $.connectors.ifReq }}'
  billing:
    heading: '{{ $.connectors.ceAzure.steps.billingExports }}'
    subHeading: Billing Export provides detailed billing data across Azure subscriptions to help you analyze your spend.
    instruction: Please follow the instructions to provide access to the Billing export for the specified Tenant ID
    login: 'and login to your Azure account'
    launchAzureConsole: Launch Azure Console
    instructions:
      i1: Login to your Azure account if not logged in already.
      i2: '{{ $.connectors.ceAws.cur.instructions.i2 }}'
      i3: ' instructions to create the Billing Export '
      i4: Enter Storage account name, Subscription ID and Storage Container, Directory name below.
    tooltipInstruction: Provided in the delivery options when the template is opened in the Azure console
    tooltipBtn: '{{ $.connectors.showInstructions }}'
    storageAccountName: Storage Account Name
    storageAccountNameRegexError: It must be 3 to 24 characters long, and can contain only lowercase letters and numbers.
    subscriptionId: Storage Account Subscription ID
    containerName: Storage Container
    directoryName: Storage Directory
    reportName: '{{ $.common.reportName }}'
    extension:
      createBillingExportGuide: How to Create a Billing Export?
      step0: After logging into Azure billing export
      step1: Click on Add to create a new Export.
      step2: In Export Details, provide Name
      step3: For Export type, select "Daily export of month-to-date costs
      step4: Leave the Start date as Today
      step5: For the Storage, select Use existing or Create new.
      step6: If use existing
      step7: Select the Subscription where your storage account is present
      step8: Select the Storage account
      step9: If create new
      step10: Select the Subscription where you want to create the storage account
      step11: Select Resource group name for this storage account
      step12: Provide the Storage account name
      step13: Provide the Location
      step14: Provide the Container name
      step15: Provide the Directory name
      step16: Review your export details and click on Create.
      step17: Your new export appears in the list of exports
      links: 'Useful links:'
      video: Watch help video
      docs: Harness Documentation
      createExport: Creating a Billing Export
      soon: coming soon
  existingExports:
    instruction: 'The following {{ reportCount }} Billing Exports are connected with your Harness Account.'
    createNewExportBtn: 'Create new Billing Export'
    subscriptionId: Subscription Id
    tenantId: '{{ $.connectors.tenantId }}'
    hints:
      nextStepHint1: 'If the Azure tenant ID you entered is covered by any of the above, select and click “Continue >” to proceed.'
      nextStepHint2: '{{ $.connectors.ceAws.curExising.nextStepHint2 }}'
    searchBillingReports: Enter billing report name
  chooseRequirements:
    heading: '{{ $.connectors.ceAws.steps.req }}'
    subHeading: Harness uses Multitenant app to sync billing export data from source storage account to Harness. Create a service principal for this app in your Azure account and assign read permissions on that particular storage account.
    featureDesc: '{{ $.connectors.ceAws.crossAccountRoleStep1.description }}'
    info: Cost visibility of the resources for which you added the Billing Export in the previous step is enabled by default. Select the others as per your requirements.
    visibilityCardDesc: Cost insights, anomaly detection, service insights, creating budgets perspectives and alerts, utilised/wasted resources in clusters.
    optimizationCardDesc: Detection of orphaned resources, recommendations to save costs, scaling/tearing down, turning off in non-work hours, reserving instances.
    visibility:
      feat1: Azure costs by services, accounts, etc.
      feat2: Cost perspective by various constructs
      feat3: Cost anomaly detection
      feat4: Budgets and forecasts
      feat5: Email and Slack alerts
      footer: from Billing export
    optimization:
      feat1: Orchestrate VMs based on idleness
      feat2: Set dependencies between VMs
      feat3: Granular savings visibility
      feat4: Simple one-time setup
      prefix: AZURE OPTIMIZATION BY
      footer1: by adding
      footer2: to SP
  servicePrincipal:
    heading: '{{ $.connectors.ceAzure.steps.servicePrincipal }}'
    subHeading1: Harness uses a multi-tenant app to sync billing export data from the source storage account to Harness and to perform cost optimization functions.
    subHeading2: 'Run the following bash commands using your bash terminal or Azure cloud shell:'
    registerCommand: '# Register the Harness app'
    costVisibilityCmd: '# Role assignment for enabling Cost Visibility'
    assignRoleCmd: '# Assign role to the app on the scope fetched above'
    optimisationCmd: '# Role assignment for enabling Cost Optimization using Autostopping'
  testConnection:
    heading: '{{ $.common.labelTestConnection }}'
    validatePermission: '{{ $.connectors.testConnectionStep.validationText.azure }}'
    verifyExport: Verifying Azure Billing Export setup
  validation:
    storageAccountName: Storage account name is required
    directoryName: Directory name is required
    containerName: Container name is required
    reportName: '{{ $.common.reportNameRequired }}'
    subscriptionId: Subscription Id is required
    tenantId: '{{ $.connectors.tenantIdRequired }}'
ceGcp:
  gcp: 'gcp'
  overview:
    heading: '{{ $.overview }}'
    projectIdLabel: 'Specify Project Id'
  billingExport:
    heading: 'Setup Billing Export'
    description: 'Cloud Billing export to BigQuery enables you to export detailed Google Cloud billing data (such as usage and cost estimate data) automatically throughout the day to a BigQuery dataset that you specify.'
    followInstruction: 'Please follow the instructions to provide create a Billing export for the specified Project Id'
    launchTemplate: 'Launch GCP console'
    datasetIdLabel: 'Dataset Name'
    tableIdLabel: 'Table Name'
  billingExtention:
    heading: 'How to create GCP Billing Export and find DataSet Name?'
    prerequisite: 'Pre-Requisite:A project where the Cloud Billing data will be stored with billing enabled on the project.'
    step1: 'Create a BigQuery dataset in which to store the data(Recommended) / Or use Existing DataSet (Harness Docs)'
    step2: '{{ $.connectors.ceGcp.grantPermission.step1}}'
    step3:
      p1: 'Click on Create Dataset, enter a '
      p2: '{{ $.connectors.ceGcp.billingExport.datasetIdLabel }}'
      p3: ' and click on create.'
    step4: 'Enable Cloud Billing export of cost data and pricing data to be written into the dataset.'
    step5: 'Open the console -> Navigation menu (menu), and then select Billing.'
    step6: 'In the Billing navigation menu, select Billing export.'
    step7: 'Select the BigQuery export tab (this tab is selected by default). On the BigQuery export tab, enable Daily cost detail.'
    otherLinks: 'Other Links:'
    link1: 'https://cloud.google.com/billing/docs/how-to/export-data-bigquery-setup'
    link2: 'Harness Docs ()'
  chooseRequirements:
    name: '{{ $.connectors.ceAws.steps.req }}'
    heading: '{{ $.connectors.ceAws.steps.req }}'
    choosePermissions: Choose Required Permissions
    description: 'Select the Cloud Cost Management features you would like to use on the GCP account.'
    info: (GCP cost Visibility is available by default. Select the others as per your requirements)
    cardDetails:
      billing:
        feat1: 'GCP costs by product, project, etc.'
        feat2: '{{$.connectors.ceAzure.chooseRequirements.visibility.feat2}}'
        feat3: '{{$.connectors.ceAzure.chooseRequirements.visibility.feat3}}'
        feat4: '{{$.connectors.ceAzure.chooseRequirements.visibility.feat4}}'
        feat5: '{{$.connectors.ceAzure.chooseRequirements.visibility.feat5}}'
        footer: 'from Billing Export'
      visibility:
        feat1: 'GCE VMs'
        feat2: 'Unused disks and snapshots'
      optimization:
        prefix: '{{$.connectors.ceGcp.gcp}} OPTIMIZATION BY'
        feat1: 'Orchestrate GCE VMs based on idleness'
        feat2: '{{$.connectors.ceAzure.chooseRequirements.optimization.feat2}}'
        feat3: '{{$.connectors.ceAzure.chooseRequirements.optimization.feat3}}'
        feat4: '{{$.connectors.ceAzure.chooseRequirements.optimization.feat4}}'
        footer: 'to service account'
  grantPermission:
    heading: 'Grant Permissions'
    bigQueryButtonText: 'Open BigQuery Page'
    step1: 'Sign in to the Google Cloud Console and go to the BigQuery page.'
    step2: 'Click Your-Project-Name in the left panel.'
    step3: 'Select your dataset in your project.'
    step4: 'Click Share Dataset. The Data permissions panel opens.'
    step5: 'Specify Harness’ service account to add member:'
    step6: 'Select BigQuery Data Viewer role.'
    step7: 'Click Continue.'
    optimization:
      step1: 'Navigate to IAM & Admin  in the GCP console'
      step2: 'Search for the service account: {{serviceAccount}}'
      step3: 'Click on Edit Principal and add Editor role available in the Basic category'
  testConnection:
    heading: '{{ $.common.labelTestConnection }}'
    step1: 'Verifying GCP connector setup'
    error: 'Could not verify connectivity'
connectorReferenceText: "can't be deleted as it is being referenced by other entities. To see the list of entities referencing this connector,"
cantDeleteConnector: "Can't Delete Connector"
